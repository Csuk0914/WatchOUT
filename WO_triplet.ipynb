{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 세팅 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark-lee/venv/watchout/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Input, Lambda\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sys.path.append(os.path.join(os.getcwd(),\"models\"))\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "MODEL_NAME = 'faster_rcnn_resnet101_coco_11_06_2017'\n",
    "PATH_TO_CKPT = os.path.join(os.getcwd(),'watchout/models/fasterRCNN/graph/frozen_inference_graph.pb')\n",
    "PATH_TO_LABELS = os.path.join(os.getcwd(),'watchout/data/deepfashion_label_map.pbtxt')\n",
    "NUM_CLASSES = 50\n",
    "detection_graph = tf.Graph()\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (15, 10)\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_path(subpath,target):\n",
    "    return subpath+\"/\"+target\n",
    "\n",
    "def create_image_path(path):\n",
    "    return os.path.join(os.getcwd(),'watchout/data/raw_deepfashion_dataset/Img/'+path)\n",
    "\n",
    "def random_sample(batch=1):\n",
    "    ann = Anno(os.path.join(os.getcwd(), 'watchout/data/raw_deepfashion_dataset/Anno'))\n",
    "    t_labels = []\n",
    "    t_paths = []\n",
    "    p_paths = []\n",
    "    n_labels = []\n",
    "    n_paths = []\n",
    "    for i in range(batch):\n",
    "        \n",
    "        ran = random.randrange(0,len(ann))\n",
    "        target_path, target_label = (ann.loc[ran]['image_name'],ann.loc[ran]['category_label'])\n",
    "        positive_ran = random.choice(ann[ann['category_label']==target_label].index.values)\n",
    "        positive_path = ann[ann['category_label']==target_label].loc[positive_ran]['image_name']\n",
    "\n",
    "        while target_path == positive_path:\n",
    "            print('loop with \"target_path == positive_path\"')\n",
    "            positive_ran = random.choice(ann[ann['category_label']==target_label].index.values)\n",
    "            positive_path = ann[ann['category_label']==target_label].loc[positive_ran]['image_name']    \n",
    "\n",
    "        negative_ran = random.choice(ann[ann['category_label']!=target_label].index.values)\n",
    "        negative_path = ann[ann['category_label']!=target_label].loc[negative_ran]['image_name']\n",
    "        negative_label = ann[ann['category_label']!=target_label].loc[negative_ran]['category_label']\n",
    "        \n",
    "        t_labels.append(target_label)\n",
    "        t_paths.append(create_image_path(target_path))\n",
    "        p_paths.append(create_image_path(positive_path))\n",
    "        n_labels.append(negative_label)\n",
    "        n_paths.append(create_image_path(negative_path))\n",
    "        \n",
    "    return (t_labels, t_paths, p_paths), (n_labels,n_paths)\n",
    "    \n",
    "def Anno(path,head=False):\n",
    "    category_path =create_path(path,\"list_category_img.txt\")\n",
    "    category_data = pd.read_csv(category_path,sep=r\"\\s*\",skiprows=[0],header=0)\n",
    "    if head:\n",
    "        return category_data.head(100)\n",
    "    return category_data\n",
    "\n",
    "def promising_box_index(scores):\n",
    "    for idx, score in enumerate(scores):\n",
    "        if score < 0.8: # 0.8 이상의 box만 리턴!\n",
    "            return idx\n",
    "    return len(scores)\n",
    "\n",
    "def promising_boxes(boxes,scores):\n",
    "    promising_idx = promising_box_index(scores)\n",
    "    return tf.slice(tf.squeeze(boxes),[0,0],[promising_idx,4])\n",
    "\n",
    "def images_from_paths(targets, positives, negatives):\n",
    "    assert len(targets) == len(positives) and len(positives) == len(negatives)\n",
    "    t_list = []\n",
    "    p_list = []\n",
    "    n_list = []\n",
    "    for t,p,n in zip(targets,positives,negatives):\n",
    "        t_single, p_single, n_single = image_from_path(t,p,n)\n",
    "        t_list.append(t_single)\n",
    "        p_list.append(p_single)\n",
    "        n_list.append(n_single)\n",
    "    \n",
    "    return np.array(t_list), np.array(p_list), np.array(n_list)\n",
    "\n",
    "def image_from_path(target, positive, negative):\n",
    "    tmp_a = Image.open(target)\n",
    "    tmp_p = Image.open(positive)\n",
    "    tmp_n = Image.open(negative)\n",
    "    \n",
    "    # arr = array(img, dtype=\"float32\")\n",
    "    \n",
    "    anchor = tmp_a.copy()\n",
    "    anchor = anchor.resize((299, 299), Image.ANTIALIAS)\n",
    "    anchor = np.array(anchor, dtype=\"float32\")\n",
    "    pos = tmp_p.copy()\n",
    "    pos = pos.resize((299,299), Image.ANTIALIAS)\n",
    "    pos = np.array(pos, dtype=\"float32\")\n",
    "    neg = tmp_n.copy()\n",
    "    neg = neg.resize((299,299), Image.ANTIALIAS)\n",
    "    neg = np.array(neg, dtype=\"float32\")\n",
    "    \n",
    "    tmp_a.close()\n",
    "    tmp_p.close()\n",
    "    tmp_n.close()\n",
    "    \n",
    "    return anchor/255.0, pos/255.0, neg/255.0\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    anchor, target = vects\n",
    "    #return K.sqrt(K.maximum(K.sum(K.square(anchor - target), axis=1, keepdims=True), K.epsilon()))\n",
    "    return K.sum(K.square(anchor - target), axis=1, keepdims=True)\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "        margin = K.constant(0.2)\n",
    "        return K.mean(K.maximum(K.constant(0), K.square(y_pred[:,0,0]) - K.square(y_pred[:,1,0]) + margin))\n",
    "\n",
    "def get_triplet_model(intermediate=False):\n",
    "    inceptionv3_input = Input(shape=(299,299,3))\n",
    "    inceptionv3_f = InceptionV3(include_top=False, weights='imagenet', input_tensor=inceptionv3_input)\n",
    "    net = inceptionv3_f.output\n",
    "    net = Flatten(name='flatten')(net)\n",
    "    net = Dense(1024, activation='relu', name='embedded')(net)\n",
    "    \n",
    "    base_model = Model(inceptionv3_f.input, net, name='base_inceptionv3')\n",
    "    if intermediate:\n",
    "        return base_model\n",
    "    \n",
    "    input_anchor = Input(shape=(299,299,3),name='input_anchor')\n",
    "    input_positive = Input(shape=(299,299,3),name='input_pos')\n",
    "    input_negative = Input(shape=(299,299,3),name='input_neg')\n",
    "    \n",
    "    net_anchor = base_model(input_anchor)\n",
    "    net_positive = base_model(input_positive)\n",
    "    net_negative = base_model(input_negative)\n",
    "    if intermediate:\n",
    "        return Model([input_anchor,input_positive,input_negative],\n",
    "                     [net_anchor,net_positive,net_negative], name='triplet_model')\n",
    "    \n",
    "    d_positive = Lambda(euclidean_distance, name='d_pos')([net_anchor, net_positive])#euclidean_distance((net_anchor, net_positive))\n",
    "    d_negative = Lambda(euclidean_distance, name='d_neg')([net_anchor, net_negative])#euclidean_distance((net_anchor, net_negative))\n",
    "    d_stacked = Lambda(lambda vects: K.stack(vects, axis=1), name='d_stacked')([d_positive, d_negative])\n",
    "    \n",
    "    triplet_model = Model([input_anchor,input_positive,input_negative], d_stacked, name='triplet_model')\n",
    "    return triplet_model\n",
    "\n",
    "def get_detector_graph():\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    return detection_graph\n",
    "\n",
    "def get_latest_weights_and_global_step(_path):\n",
    "    files = os.listdir(path=_path)\n",
    "    print('weights list:'+str(files))\n",
    "    files.reverse()\n",
    "    return files[0],int(files[0].split('-')[1].split('.')[0])\n",
    "\n",
    "def get_train_data(_batch,d_sess):\n",
    "    (t_lbl, t_path, p_path), (n_lbl, n_path) = random_sample(_batch)\n",
    "\n",
    "    anchor, positive, negative = images_from_paths(t_path, p_path, n_path)\n",
    "\n",
    "    print('초기 anchor,positive,negative shape')\n",
    "    print(anchor.shape)\n",
    "    print(positive.shape)\n",
    "    print(negative.shape)\n",
    "\n",
    "    for idx,single_batch in enumerate(t_path):\n",
    "\n",
    "        image = Image.open(single_batch)\n",
    "        image_np = load_image_into_numpy_array(image)\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "        (_image_tensor,_boxes, scores, classes, num) = d_sess.run(\n",
    "          [image_tensor, detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "        target_boxes = promising_boxes(_boxes, scores[0])\n",
    "        len_target_boxes = int(target_boxes.shape[0])\n",
    "\n",
    "        cropped_images = []\n",
    "        for box in target_boxes.eval().tolist():\n",
    "            current_cropped_image = tf.image.crop_and_resize(image=image_np_expanded/255.0,\n",
    "                                                             boxes=[box],\n",
    "                                                             box_ind=[0],\n",
    "                                                             crop_size=[299,299])\n",
    "            cropped_images.append(current_cropped_image[0])\n",
    "            anchor= np.append(anchor,np.expand_dims(current_cropped_image[0].eval(),axis=0),axis=0)\n",
    "            positive = np.append(positive,np.expand_dims(positive[idx],axis=0),axis=0)\n",
    "            negative = np.append(negative,np.expand_dims(negative[idx],axis=0),axis=0)\n",
    "    \n",
    "    print('후기 anchor, positive, negative shape')\n",
    "    print(anchor.shape)\n",
    "    print(positive.shape)\n",
    "    print(negative.shape)\n",
    "\n",
    "    assert anchor.shape[0] == positive.shape[0] and positive.shape[0] == negative.shape[0]\n",
    "    \n",
    "    return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OD + Triplet 결합 & Triplet만 학습하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35683742 0.         0.         ... 0.         0.         0.        ]]\n",
      "2.8359787\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "triplet_graph = tf.Graph()\n",
    "\n",
    "\"\"\"with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\"\"\"\n",
    "a = None\n",
    "b = None\n",
    "c = None\n",
    "\n",
    "def get_triplet_model(intermediate=False):\n",
    "    inceptionv3_input = Input(shape=(299,299,3))\n",
    "    inceptionv3_f = InceptionV3(include_top=False, weights='imagenet', input_tensor=inceptionv3_input)\n",
    "    net = inceptionv3_f.output\n",
    "    net = Flatten(name='flatten')(net)\n",
    "    net = Dense(1024, activation='relu', name='embedded')(net)\n",
    "    \n",
    "    base_model = Model(inceptionv3_f.input, net, name='base_inceptionv3')\n",
    "    if intermediate:\n",
    "        return base_model\n",
    "    \n",
    "    input_anchor = Input(shape=(299,299,3),name='input_anchor')\n",
    "    input_positive = Input(shape=(299,299,3),name='input_pos')\n",
    "    input_negative = Input(shape=(299,299,3),name='input_neg')\n",
    "    \n",
    "    net_anchor = base_model(input_anchor)\n",
    "    net_positive = base_model(input_positive)\n",
    "    net_negative = base_model(input_negative)\n",
    "    if intermediate:\n",
    "        return Model([input_anchor,input_positive,input_negative],\n",
    "                     [net_anchor,net_positive,net_negative], name='triplet_model')\n",
    "    \n",
    "    d_positive = Lambda(euclidean_distance, name='d_pos')([net_anchor, net_positive])#euclidean_distance((net_anchor, net_positive))\n",
    "    d_negative = Lambda(euclidean_distance, name='d_neg')([net_anchor, net_negative])#euclidean_distance((net_anchor, net_negative))\n",
    "    d_stacked = Lambda(lambda vects: K.stack(vects, axis=1), name='d_stacked')([d_positive, d_negative])\n",
    "    \n",
    "    triplet_model = Model([input_anchor,input_positive,input_negative], d_stacked, name='triplet_model')\n",
    "    return triplet_model\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    anchor, target = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(anchor - target), axis=1, keepdims=True), K.epsilon()))\n",
    "    #return K.sum(K.square(anchor - target), axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "        margin = K.constant(0.2)\n",
    "        \"\"\"print(y_pred[:,0,0])\n",
    "        print(K.square(y_pred[:,0,0]))\n",
    "        print(y_pred[:,1,0])\n",
    "        print(K.square(y_pred[:,1,0]))\"\"\"\n",
    "        \"\"\"return K.mean(K.maximum(K.constant(0),\n",
    "                                K.square(y_pred[:,0,0]) - K.square(y_pred[:,1,0]) + margin))\"\"\"\n",
    "        return K.mean(K.maximum(K.constant(0), y_pred[:,0,0] - y_pred[:,1,0] + margin))\n",
    "    \n",
    "with tf.Session(graph=triplet_graph) as triplet_sess:\n",
    "    K.set_learning_phase(1)\n",
    "    # 모델 resume 필요\n",
    "    triplet_model = get_triplet_model(True)\n",
    "    triplet_model.compile(optimizer=Adam(lr=1e-7) ,loss='mean_squared_error')\n",
    "    triplet_sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    batch = 1\n",
    "    (t_lbl, t_path, p_path), (n_lbl, n_path) = random_sample(batch)\n",
    "\n",
    "    anchor, positive, negative = images_from_paths(t_path, p_path, n_path)\n",
    "    #print(anchor[0][0][0:5])\n",
    "    #print(triplet_model.summary())\n",
    "    #for i in range(4):\n",
    "        #print(triplet_sess.run(triplet_model.layers[3].get_output_at(i),\n",
    "        #                       feed_dict={'input_anchor':anchor,'input_pos':positive,'input_neg':negative}))\n",
    "    #print(triplet_model.layers[len(triplet_model.layers)-1].output)\n",
    "    \n",
    "    a=triplet_sess.run(triplet_model.layers[len(triplet_model.layers)-1].output, feed_dict={'input_1:0':anchor})\n",
    "    b=triplet_sess.run(triplet_model.layers[len(triplet_model.layers)-1].output, feed_dict={'input_1:0':positive})\n",
    "    c=triplet_sess.run(triplet_model.layers[len(triplet_model.layers)-1].output, feed_dict={'input_1:0':negative})\n",
    "    print(triplet_sess.run(triplet_model.layers[len(triplet_model.layers)-1].output, feed_dict={'input_1:0':anchor}))\n",
    "    \n",
    "    true_model = get_triplet_model()\n",
    "    true_model.compile(optimizer=Adam(lr=1e-7) ,loss=triplet_loss)\n",
    "    #true_model.fit(x=[anchor,positive,negative], y=np.random.randint(2, size=(1,2,1)).T)\n",
    "    print(true_model.train_on_batch(x=[anchor, positive, negative],\n",
    "                                            y=np.random.randint(2, size=(1,2,1)).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(526.8052, 462.05658)\n",
      "64.94859619140625\n"
     ]
    }
   ],
   "source": [
    "# 모델() 2.8\n",
    "# 실계산\n",
    "def np_euclidean(a,b):\n",
    "    return np.sum(np.square(a-b))\n",
    "def np_triplet(pos,neg):\n",
    "    return np.mean(np.maximum(0,pos-neg+0.2))\n",
    "from numpy import linalg as LA\n",
    "from sklearn import preprocessing\n",
    "#from tensorflow.contrib.losses.metric_learning import triplet_semihard_loss\n",
    "d__pos = np_euclidean(a,b)\n",
    "d__neg = np_euclidean(a,c)\n",
    "print((d__pos,d__neg))\n",
    "print(np_triplet(d__pos,d__neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        from tensorflow.contrib.losses.metric_learning import triplet_semihard_loss\n",
    "        triplet_semihard_loss([1,1,2],[anchor,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2c504c3bed32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     print(layer.output)\"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtriplet_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#layers[3].output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \"\"\"\n\u001b[0;32m--> 648\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4756\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4757\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4758\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "            \"\"\"for layer in triplet_model.layers:\n",
    "                print(layer)\n",
    "                #print(layer.trainable)\n",
    "                print(layer.output)\"\"\"\n",
    "            for i in range(4):\n",
    "                print(triplet_model.layers[3].get_output_at(i).eval(session=triplet_sess))#layers[3].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No weights file!\n",
      "list index out of range\n",
      "0\n",
      "초기 anchor,positive,negative shape\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "후기 anchor,positive,negative shape\n",
      "(2, 299, 299, 3)\n",
      "(2, 299, 299, 3)\n",
      "(2, 299, 299, 3)\n",
      "train done\n",
      "test done\n",
      "train done\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "triplet_graph = tf.Graph()\n",
    "keras_weights_path = os.path.join(os.getcwd(),'watchout/models/tripletnetwork/checkpoint')\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        \n",
    "        # triplet_graph라는 전혀 다른 graph object를 할당한 session에서 실행\n",
    "        with tf.Session(graph=triplet_graph) as triplet_sess:\n",
    "            global_step = tf.get_variable('global_step', initializer=0, trainable=False)\n",
    "            increment_global_step = tf.assign(global_step, global_step+1)\n",
    "            \n",
    "            # 모델 resume 필요\n",
    "            triplet_model = get_triplet_model()\n",
    "            \n",
    "            triplet_sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            try:\n",
    "                latest_weights, global_step_value = get_latest_weights_and_global_step(keras_weights_path)\n",
    "                triplet_sess.run(global_step.assign(global_step_value))\n",
    "            except Exception as e:\n",
    "                print('No weights file!')\n",
    "                print(e)\n",
    "            \n",
    "            print(global_step.eval())\n",
    "            #c = 1/0\n",
    "            \n",
    "            triplet_model.compile(optimizer=Adam(lr=1e-7), loss=triplet_loss)\n",
    "            #keras_tensorboard = TensorBoard(log_dir=\"./watchout/models/tripletnetwork/logs/{}\".format(time()))\n",
    "            #keras_checkpoint = ModelCheckpoint('./watchout/models/tripletnetwork/checkpoint/weights.best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='min')\n",
    "            \n",
    "            train_writer = tf.summary.FileWriter('./watchout/models/tripletnetwork/logs/train', triplet_sess.graph)\n",
    "            test_writer = tf.summary.FileWriter('./watchout/models/tripletnetwork/logs/test')\n",
    "\n",
    "            batch = 1\n",
    "            (t_lbl, t_path, p_path), (n_lbl, n_path) = random_sample(batch)\n",
    "\n",
    "            anchor, positive, negative = images_from_paths(t_path, p_path, n_path)\n",
    "\n",
    "            print('초기 anchor,positive,negative shape')\n",
    "            print(anchor.shape)\n",
    "            print(positive.shape)\n",
    "            print(negative.shape)\n",
    "            \n",
    "            for idx,single_batch in enumerate(t_path):\n",
    "                \n",
    "                image = Image.open(single_batch)\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                (_image_tensor,_boxes, scores, classes, num) = sess.run(\n",
    "                  [image_tensor, detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                  feed_dict={image_tensor: image_np_expanded})\n",
    "                \n",
    "                target_boxes = promising_boxes(_boxes, scores[0])\n",
    "                len_target_boxes = int(target_boxes.shape[0])\n",
    "                \n",
    "                cropped_images = []\n",
    "                for box in target_boxes.eval().tolist():\n",
    "                    current_cropped_image = tf.image.crop_and_resize(image=image_np_expanded/255.0,\n",
    "                                                                     boxes=[box],\n",
    "                                                                     box_ind=[0],\n",
    "                                                                     crop_size=[299,299])\n",
    "                    cropped_images.append(current_cropped_image[0])\n",
    "                    anchor= np.append(anchor,np.expand_dims(current_cropped_image[0].eval(),axis=0),axis=0)\n",
    "                    positive = np.append(positive,np.expand_dims(positive[idx],axis=0),axis=0)\n",
    "                    negative = np.append(negative,np.expand_dims(negative[idx],axis=0),axis=0)\n",
    "            \n",
    "            print('후기 anchor,positive,negative shape')\n",
    "            print(anchor.shape)\n",
    "            print(positive.shape)\n",
    "            print(negative.shape)\n",
    "            \n",
    "            assert anchor.shape[0] == positive.shape[0] and positive.shape[0] == negative.shape[0]\n",
    "            \n",
    "            #################\n",
    "            \n",
    "            #anchor, positive, negative = get_train_data(batch=1)\n",
    "            final_batch = anchor.shape[0]\n",
    "            \n",
    "            for n in range(2):\n",
    "                training_loss = triplet_model.train_on_batch(x=[anchor, positive, negative],\n",
    "                                            y=np.random.randint(2, size=(1,2,final_batch)).T)\n",
    "                triplet_sess.run(increment_global_step)\n",
    "                train_summary = tf.Summary(value=[tf.Summary.Value(tag=\"train_loss\", \n",
    "                                             simple_value=training_loss)])\n",
    "                train_writer.add_summary(train_summary,global_step.eval())\n",
    "                \n",
    "                print('train done')\n",
    "                \n",
    "                if n % 2 == 0:\n",
    "                    (_t_lbl, _t_path, _p_path), (_n_lbl, _n_path) = random_sample(30)\n",
    "\n",
    "                    _anchor, _positive, _negative = images_from_paths(_t_path, _p_path, _n_path)\n",
    "                    test_loss = triplet_model.test_on_batch(x=[_anchor, _positive, _negative],\n",
    "                                            y=np.random.randint(2, size=(1,2,30)).T)\n",
    "                    test_summary = tf.Summary(value=[tf.Summary.Value(tag=\"test_loss\", \n",
    "                                             simple_value=test_loss)])\n",
    "                    test_writer.add_summary(test_summary,global_step.eval())\n",
    "                    print('test done')\n",
    "\n",
    "            triplet_model.save_weights(os.path.join(os.getcwd(),'watchout/models/tripletnetwork/checkpoint/weights.best.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-792cfaf6b280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mnum_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_detections:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\"\"\"triplet_graph = tf.Graph()\n",
    "keras_weights_path = os.path.join(os.getcwd(),'watchout/models/tripletnetwork/checkpoint')\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        \n",
    "# triplet_graph라는 전혀 다른 graph object를 할당한 session에서 실행\n",
    "def get_latest_weights_and_global_step(_path):\n",
    "    files = os.listdir(path=_path)\n",
    "    files.reverse()\n",
    "    return files[0],int(files[0].split('-')[1].split('.')[0])\n",
    "\n",
    "with tf.Session(graph=triplet_graph) as triplet_sess:\n",
    "    global_step = tf.get_variable('global_step', initializer=0, trainable=False)\n",
    "    increment_global_step = tf.assign(global_step, global_step+1)\n",
    "\n",
    "    # 모델 resume 필요\n",
    "    #triplet_model = get_triplet_model()\n",
    "    triplet_sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        latest_weights, global_step_value = get_latest_weights_and_global_step(keras_weights_path)\n",
    "        #triplet_model.load_weights(latest_weights)\n",
    "        triplet_sess.run(global_step.assign(global_step_value))\n",
    "        print(latest_weights)\n",
    "        print(global_step_value)\n",
    "    except Exception as e:\n",
    "        print('except')\n",
    "        print(e)\n",
    "    print(global_step.eval())\"\"\"\n",
    "def image_from_path(target, positive, negative):\n",
    "    tmp_a = Image.open(target)\n",
    "    tmp_p = Image.open(positive)\n",
    "    tmp_n = Image.open(negative)\n",
    "    \n",
    "    # arr = array(img, dtype=\"float32\")\n",
    "    \n",
    "    anchor = tmp_a.copy()\n",
    "    anchor = anchor.resize((299, 299), Image.ANTIALIAS)\n",
    "    anchor = np.array(anchor, dtype=\"float32\")\n",
    "    pos = tmp_p.copy()\n",
    "    pos = pos.resize((299,299), Image.ANTIALIAS)\n",
    "    pos = np.array(pos, dtype=\"float32\")\n",
    "    neg = tmp_n.copy()\n",
    "    neg = neg.resize((299,299), Image.ANTIALIAS)\n",
    "    neg = np.array(neg, dtype=\"float32\")\n",
    "    \n",
    "    tmp_a.close()\n",
    "    tmp_p.close()\n",
    "    tmp_n.close()\n",
    "    \n",
    "    return anchor/255.0, pos/255.0, neg/255.0\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        \n",
    "        a,p,n=get_train_data(1,sess)\n",
    "        print(a.shape)\n",
    "        print(p.shape)\n",
    "        print(n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights list:['.DS_Store', 'weights-0.hdf5', 'weights-99.hdf5', 'weights.best.hdf5']\n",
      "['weights.best.hdf5', 'weights-99.hdf5', 'weights-0.hdf5', '.DS_Store']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-a9876c728468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_latest_weights_and_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-a9876c728468>\u001b[0m in \u001b[0;36mget_latest_weights_and_global_step\u001b[0;34m(_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_latest_weights_and_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def get_latest_weights_and_global_step(_path):\n",
    "    files = os.listdir(path=_path)\n",
    "    print('weights list:'+str(files))\n",
    "    files.reverse()\n",
    "    print(files)\n",
    "    return files[0],int(files[0].split('-')[1].split('.')[0])\n",
    "print(get_latest_weights_and_global_step(keras_weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref> cannot be interpreted as a Tensor. (Tensor Tensor(\"conv2d_1/kernel:0\", shape=(3, 3, 3, 32), dtype=float32_ref) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    276\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 277\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    278\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3322\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3401\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3402\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3403\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"conv2d_1/kernel:0\", shape=(3, 3, 3, 32), dtype=float32_ref) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-37ac89ffe4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtriplet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'watchout/models/tripletnetwork/checkpoint/weights.best.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   2585\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m         \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \"\"\"\n\u001b[1;32m   2201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2203\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1113\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \"\"\"\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \"\"\"\n\u001b[1;32m    346\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \"\"\"\n\u001b[1;32m    346\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/venv/watchout/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 284\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    285\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref> cannot be interpreted as a Tensor. (Tensor Tensor(\"conv2d_1/kernel:0\", shape=(3, 3, 3, 32), dtype=float32_ref) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "            triplet_model.save_weights(os.path.join(os.getcwd(),'watchout/models/tripletnetwork/checkpoint/weights.best.hdf5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
